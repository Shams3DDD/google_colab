{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Shams3DDD/google_colab/blob/main/%D0%9A%D0%BE%D0%BF%D0%B8%D1%8F_%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%D0%B0_%22%D0%91%D0%B0%D0%B7%D0%BE%D0%B2%D1%8B%D0%B9_%D0%B1%D0%BB%D0%BE%D0%BA_%7C_%D0%98%D0%BD%D1%82%D0%B5%D0%B3%D1%80%D0%B0%D1%86%D0%B8%D1%8F_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D0%BE%D0%B9_%D1%81%D0%B5%D1%82%D0%B8_%D0%BD%D0%B0_%D0%94%D0%95%D0%9C%D0%9E_%D0%9F%D0%90%D0%9D%D0%95%D0%9B%D0%AC_%7C_%D0%94%D0%97_Pro_%7C_%D0%A3%D0%98%D0%98%22.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6nTn8IaLGn_"
      },
      "source": [
        "Необходимо создать, обучить нейронную сеть с точностью не менее 85% и упаковать её в архив для загрузки на демо-панель:\n",
        "* создать нейронную сеть для распознавания марки автомобиля из 3х вариантов\n",
        "* сохраните веса\n",
        "* подготовить запуск модели \"из коробки\"\n",
        "* подготовить архив с готовой нейронной сетью для загрузки в демо-панель\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ykPHyiP0YCcx"
      },
      "source": [
        "# Загрузка данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "F8rGjdfMOTi6"
      },
      "outputs": [],
      "source": [
        "# Работа с массивами\n",
        "import numpy as np\n",
        "\n",
        "# Генератор аугментированных изображений\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Основа для создания последовательной модели\n",
        "from tensorflow.keras.models import Sequential\n",
        "\n",
        "# Основные слои\n",
        "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
        "\n",
        "# Оптимизатор\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Матрица ошибок классификатора\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "from PIL import Image, ImageOps\n",
        "\n",
        "# Подключение модуля для загрузки данных из облака\n",
        "import gdown\n",
        "\n",
        "# Инструменты для работы с файлами\n",
        "import os\n",
        "\n",
        "# Отрисовка графиков\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Рисование графиков в ячейках Colab\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n"
          ]
        }
      ],
      "source": [
        "# Задание гиперпараметров\n",
        "\n",
        "TRAIN_PATH = \"/content/cars\"  # Папка для обучающего набора данных\n",
        "TEST_PATH = \"/content/cars_test\"  # Папка для тестового набора данных\n",
        "\n",
        "TEST_SPLIT = 0.1  # Доля тестовых данных в общем наборе\n",
        "VAL_SPLIT = 0.2  # Доля проверочной выборки в обучающем наборе\n",
        "\n",
        "IMG_WIDTH = 128  # Ширина изображения для нейросети\n",
        "IMG_HEIGHT = 64  # Высота изображения для нейросети\n",
        "IMG_CHANNELS = 3  # Количество каналов (для RGB равно 3, для Grey равно 1)\n",
        "\n",
        "# Параметры аугментации\n",
        "ROTATION_RANGE = 8  # Пределы поворота\n",
        "WIDTH_SHIFT_RANGE = 0.15  # Пределы сдвига по горизонтали\n",
        "HEIGHT_SHIFT_RANGE = 0.15  # Пределы сдвига по вертикали\n",
        "ZOOM_RANGE = 0.15  # Пределы увеличения/уменьшения\n",
        "BRIGHTNESS_RANGE = (0.7, 1.3)  # Пределы изменения яркости\n",
        "HORIZONTAL_FLIP = True  # Горизонтальное отражение разрешено\n",
        "\n",
        "EPOCHS = 60  # Число эпох обучения\n",
        "BATCH_SIZE = 24  # Размер батча для обучения модели\n",
        "OPTIMIZER = Adam(0.0001)  # Оптимизатор"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'middle_fmr.zip'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Загрузка zip-архива с датасетом из облака на диск виртуальной машины colab\n",
        "gdown.download(\n",
        "    \"https://storage.yandexcloud.net/aiueducation/Content/base/l5/middle_fmr.zip\",\n",
        "    None,\n",
        "    quiet=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "checkdir:  cannot create extraction directory: /content/cars\n",
            "           No such file or directory\n"
          ]
        }
      ],
      "source": [
        "#  Для colab\n",
        "# Очистка данных от прошлого запуска (если есть)\n",
        "#!rm -rf {TRAIN_PATH} {TEST_PATH}\n",
        "\n",
        "# Разархивация датасета в директорию данных\n",
        "#!unzip -qo \"middle_fmr.zip\" -d {TRAIN_PATH}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Для vs code\n",
        "TRAIN_PATH = \"/Users/admin/Project/AIuniversity/google_colab/content/cars\"  # Папка для обучающего набора данных\n",
        "TEST_PATH = \"/Users/admin/Project/AIuniversity/google_colab/content/cars_test\"  # Папка для тестового набора данных"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Для vscode\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Указать путь к архиву и целевой директории\n",
        "zip_file_path = \"middle_fmr.zip\"\n",
        "target_directory = \"/Users/admin/Project/AIuniversity/google_colab/content/cars\"\n",
        "\n",
        "# Создать директорию, если она не существует\n",
        "Path(target_directory).mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "# Разархивировать с созданием директории\n",
        "os.system(f\"unzip -qo {zip_file_path} -d {target_directory}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Количество классов: 3, метки классов: ['Ferrari', 'Mercedes', 'Renault']\n"
          ]
        }
      ],
      "source": [
        "# Определение списка имен классов\n",
        "CLASS_LIST = sorted(os.listdir(TRAIN_PATH))\n",
        "\n",
        "# Определение количества классов\n",
        "CLASS_COUNT = len(CLASS_LIST)\n",
        "\n",
        "# Проверка результата\n",
        "print(f\"Количество классов: {CLASS_COUNT}, метки классов: {CLASS_LIST}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Размер класса Ferrari: 1088 машин, для теста выделено файлов: 108\n",
            "Размер класса Mercedes: 1161 машин, для теста выделено файлов: 116\n",
            "Размер класса Renault: 1178 машин, для теста выделено файлов: 117\n",
            "Общий размер базы: 3427, выделено для обучения: 3086, для теста: 341\n"
          ]
        }
      ],
      "source": [
        "# Перенос файлов для теста в отдельное дерево папок, расчет размеров наборов данных\n",
        "\n",
        "try:\n",
        "    os.mkdir(TEST_PATH)  # Создание папки для тестовых данных\n",
        "except:\n",
        "    pass\n",
        "\n",
        "train_count = 0\n",
        "test_count = 0\n",
        "\n",
        "for class_name in CLASS_LIST:  # Для всех классов по порядку номеров (их меток)\n",
        "    class_path = f\"{TRAIN_PATH}/{class_name}\"  # Формирование полного пути к папке с изображениями класса\n",
        "    test_path = f\"{TEST_PATH}/{class_name}\"  # Полный путь для тестовых данных класса\n",
        "    class_files = os.listdir(\n",
        "        class_path\n",
        "    )  # Получение списка имен файлов с изображениями текущего класса\n",
        "    class_file_count = len(class_files)  # Получение общего числа файлов класса\n",
        "\n",
        "    try:\n",
        "        os.mkdir(test_path)  # Создание подпапки класса для тестовых данных\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    test_file_count = int(\n",
        "        class_file_count * TEST_SPLIT\n",
        "    )  # Определение числа тестовых файлов для класса\n",
        "    test_files = class_files[\n",
        "        -test_file_count:\n",
        "    ]  # Выделение файлов для теста от конца списка\n",
        "    for f in test_files:  # Перемещение тестовых файлов в папку для теста\n",
        "        os.rename(f\"{class_path}/{f}\", f\"{test_path}/{f}\")\n",
        "    train_count += (\n",
        "        class_file_count  # Увеличение общего счетчика файлов обучающего набора\n",
        "    )\n",
        "    test_count += test_file_count  # Увеличение общего счетчика файлов тестового набора\n",
        "\n",
        "    print(\n",
        "        f\"Размер класса {class_name}: {class_file_count} машин, для теста выделено файлов: {test_file_count}\"\n",
        "    )\n",
        "\n",
        "print(\n",
        "    f\"Общий размер базы: {train_count}, выделено для обучения: {train_count - test_count}, для теста: {test_count}\"\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Подготовка и обучение модели"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Генераторы изображений\n",
        "\n",
        "# Изображения для обучающего набора нормализуются и аугментируются согласно заданным гиперпараметрам\n",
        "# Далее набор будет разделен на обучающую и проверочную выборку в соотношении VAL_SPLIT\n",
        "train_datagen = ImageDataGenerator(\n",
        "    rescale=1.0 / 255.0,\n",
        "    rotation_range=ROTATION_RANGE,\n",
        "    width_shift_range=WIDTH_SHIFT_RANGE,\n",
        "    height_shift_range=HEIGHT_SHIFT_RANGE,\n",
        "    zoom_range=ZOOM_RANGE,\n",
        "    brightness_range=BRIGHTNESS_RANGE,\n",
        "    horizontal_flip=HORIZONTAL_FLIP,\n",
        "    validation_split=VAL_SPLIT,\n",
        ")\n",
        "\n",
        "# Изображения для тестового набора только нормализуются\n",
        "test_datagen = ImageDataGenerator(rescale=1.0 / 255.0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 2469 images belonging to 3 classes.\n",
            "Found 617 images belonging to 3 classes.\n",
            "Found 341 images belonging to 3 classes.\n"
          ]
        }
      ],
      "source": [
        "# Обучающая выборка генерируется из папки обучающего набора\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "    # Путь к обучающим изображениям\n",
        "    TRAIN_PATH,\n",
        "    # Параметры требуемого размера изображения\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    # Размер батча\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    # Указание сгенерировать обучающую выборку\n",
        "    subset=\"training\",\n",
        ")\n",
        "\n",
        "# Проверочная выборка также генерируется из папки обучающего набора\n",
        "validation_generator = train_datagen.flow_from_directory(\n",
        "    TRAIN_PATH,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        "    # Указание сгенерировать проверочную выборку\n",
        "    subset=\"validation\",\n",
        ")\n",
        "\n",
        "# Тестовая выборка генерируется из папки тестового набора\n",
        "test_generator = test_datagen.flow_from_directory(\n",
        "    TEST_PATH,\n",
        "    target_size=(IMG_HEIGHT, IMG_WIDTH),\n",
        "    batch_size=test_count,\n",
        "    class_mode=\"categorical\",\n",
        "    shuffle=True,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Формы данных тренировочной выборки: (24, 64, 128, 3), (24, 3), батчей: 103\n",
            "Формы данных   проверочной выборки: (24, 64, 128, 3), (24, 3), батчей: 26\n",
            "Формы данных      тестовой выборки: (341, 64, 128, 3), (341, 3), батчей: 1\n",
            "\n",
            "Метки классов тренировочной выборки: {'Ferrari': 0, 'Mercedes': 1, 'Renault': 2}\n",
            "Метки классов   проверочной выборки: {'Ferrari': 0, 'Mercedes': 1, 'Renault': 2}\n",
            "Метки классов      тестовой выборки: {'Ferrari': 0, 'Mercedes': 1, 'Renault': 2}\n"
          ]
        }
      ],
      "source": [
        "# Проверка формы данных\n",
        "print(\n",
        "    f\"Формы данных тренировочной выборки: {train_generator[0][0].shape}, {train_generator[0][1].shape}, батчей: {len(train_generator)}\"\n",
        ")\n",
        "print(\n",
        "    f\"Формы данных   проверочной выборки: {validation_generator[0][0].shape}, {validation_generator[0][1].shape}, батчей: {len(validation_generator)}\"\n",
        ")\n",
        "print(\n",
        "    f\"Формы данных      тестовой выборки: {test_generator[0][0].shape}, {test_generator[0][1].shape}, батчей: {len(test_generator)}\"\n",
        ")\n",
        "\n",
        "print()\n",
        "\n",
        "# Проверка назначения меток классов\n",
        "print(f\"Метки классов тренировочной выборки: {train_generator.class_indices}\")\n",
        "print(f\"Метки классов   проверочной выборки: {validation_generator.class_indices}\")\n",
        "print(f\"Метки классов      тестовой выборки: {test_generator.class_indices}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функция компиляции и обучения модели нейронной сети\n",
        "# По окончанию выводит графики обучения\n",
        "\n",
        "\n",
        "def compile_train_model(\n",
        "    model,  # модель нейронной сети\n",
        "    train_data,  # обучающие данные\n",
        "    val_data,  # проверочные данные\n",
        "    optimizer=OPTIMIZER,  # оптимизатор\n",
        "    epochs=EPOCHS,  # количество эпох обучения\n",
        "    batch_size=BATCH_SIZE,  # размер батча\n",
        "    figsize=(20, 5),\n",
        "):  # размер полотна для графиков\n",
        "    # Компиляция модели\n",
        "    model.compile(\n",
        "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
        "    )\n",
        "\n",
        "    # Вывод сводки\n",
        "    model.summary()\n",
        "\n",
        "    # Обучение модели с заданными параметрами\n",
        "    history = model.fit(\n",
        "        train_data,\n",
        "        epochs=epochs,\n",
        "        # batch_size=batch_size,\n",
        "        validation_data=val_data,\n",
        "    )\n",
        "\n",
        "    # Вывод графиков точности и ошибки\n",
        "    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=figsize)\n",
        "    fig.suptitle(\"График процесса обучения модели\")\n",
        "    ax1.plot(\n",
        "        history.history[\"accuracy\"], label=\"Доля верных ответов на обучающем наборе\"\n",
        "    )\n",
        "    ax1.plot(\n",
        "        history.history[\"val_accuracy\"],\n",
        "        label=\"Доля верных ответов на проверочном наборе\",\n",
        "    )\n",
        "    ax1.xaxis.get_major_locator().set_params(integer=True)\n",
        "    ax1.set_xlabel(\"Эпоха обучения\")\n",
        "    ax1.set_ylabel(\"Доля верных ответов\")\n",
        "    ax1.legend()\n",
        "\n",
        "    ax2.plot(history.history[\"loss\"], label=\"Ошибка на обучающем наборе\")\n",
        "    ax2.plot(history.history[\"val_loss\"], label=\"Ошибка на проверочном наборе\")\n",
        "    ax2.xaxis.get_major_locator().set_params(integer=True)\n",
        "    ax2.set_xlabel(\"Эпоха обучения\")\n",
        "    ax2.set_ylabel(\"Ошибка\")\n",
        "    ax2.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Функция вывода результатов оценки модели на заданных данных\n",
        "\n",
        "\n",
        "def eval_model(\n",
        "    model,\n",
        "    x,  # данные для предсказания модели (вход)\n",
        "    y_true,  # верные метки классов в формате OHE (выход)\n",
        "    class_labels=[],  # список меток классов\n",
        "    cm_round=3,  # число знаков после запятой для матрицы ошибок\n",
        "    title=\"\",  # название модели\n",
        "    figsize=(10, 10),  # размер полотна для матрицы ошибок\n",
        "):\n",
        "    # Вычисление предсказания сети\n",
        "    y_pred = model.predict(x)\n",
        "    # Построение матрицы ошибок\n",
        "    cm = confusion_matrix(\n",
        "        np.argmax(y_true, axis=1), np.argmax(y_pred, axis=1), normalize=\"true\"\n",
        "    )\n",
        "    # Округление значений матрицы ошибок\n",
        "    cm = np.around(cm, cm_round)\n",
        "\n",
        "    # Отрисовка матрицы ошибок\n",
        "    fig, ax = plt.subplots(figsize=figsize)\n",
        "    ax.set_title(f\"Нейросеть {title}: матрица ошибок нормализованная\", fontsize=18)\n",
        "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=class_labels)\n",
        "    disp.plot(ax=ax)\n",
        "    ax.images[-1].colorbar.remove()  # Стирание ненужной цветовой шкалы\n",
        "    fig.autofmt_xdate(rotation=45)  # Наклон меток горизонтальной оси\n",
        "    plt.xlabel(\"Предсказанные классы\", fontsize=16)\n",
        "    plt.ylabel(\"Верные классы\", fontsize=16)\n",
        "    plt.show()\n",
        "\n",
        "    print(\"-\" * 100)\n",
        "    print(f\"Нейросеть: {title}\")\n",
        "\n",
        "    # Для каждого класса:\n",
        "    for cls in range(len(class_labels)):\n",
        "        # Определяется индекс класса с максимальным значением предсказания (уверенности)\n",
        "        cls_pred = np.argmax(cm[cls])\n",
        "        # Формируется сообщение о верности или неверности предсказания\n",
        "        msg = \"ВЕРНО :-)\" if cls_pred == cls else \"НЕВЕРНО :-(\"\n",
        "        # Выводится текстовая информация о предсказанном классе и значении уверенности\n",
        "        print(\n",
        "            \"Класс: {:<20} {:3.0f}% сеть отнесла к классу {:<20} - {}\".format(\n",
        "                class_labels[cls],\n",
        "                100.0 * cm[cls, cls_pred],\n",
        "                class_labels[cls_pred],\n",
        "                msg,\n",
        "            )\n",
        "        )\n",
        "\n",
        "    # Средняя точность распознавания определяется как среднее диагональных элементов матрицы ошибок\n",
        "    print(\n",
        "        \"\\nСредняя точность распознавания: {:3.0f}%\".format(\n",
        "            100.0 * cm.diagonal().mean()\n",
        "        )\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Совместная функция обучения и оценки модели нейронной сети\n",
        "\n",
        "\n",
        "def compile_train_eval_model(\n",
        "    model,  # модель нейронной сети\n",
        "    train_data,  # обучающие данные\n",
        "    val_data,  # проверочные данные\n",
        "    test_data,  # тестовые данные\n",
        "    class_labels=CLASS_LIST,  # список меток классов\n",
        "    title=\"\",  # название модели\n",
        "    optimizer=OPTIMIZER,  # оптимизатор\n",
        "    epochs=EPOCHS,  # количество эпох обучения\n",
        "    batch_size=BATCH_SIZE,  # размер батча\n",
        "    graph_size=(20, 5),  # размер полотна для графиков обучения\n",
        "    cm_size=(10, 10),  # размер полотна для матрицы ошибок\n",
        "):\n",
        "    # Компиляция и обучение модели на заданных параметрах\n",
        "    # В качестве проверочных используются тестовые данные\n",
        "    compile_train_model(\n",
        "        model,\n",
        "        train_data,\n",
        "        val_data,\n",
        "        optimizer=optimizer,\n",
        "        epochs=epochs,\n",
        "        batch_size=batch_size,\n",
        "        figsize=graph_size,\n",
        "    )\n",
        "\n",
        "    # Вывод результатов оценки работы модели на тестовых данных\n",
        "    eval_model(\n",
        "        model,\n",
        "        test_data[0][0],\n",
        "        test_data[0][1],\n",
        "        class_labels=class_labels,\n",
        "        title=title,\n",
        "        figsize=cm_size,\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 64, 128, 256)      7168      \n",
            "                                                                 \n",
            " batch_normalization (Batch  (None, 64, 128, 256)      1024      \n",
            " Normalization)                                                  \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 64, 128, 256)      590080    \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 21, 42, 256)       0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_2 (Conv2D)           (None, 21, 42, 256)       590080    \n",
            "                                                                 \n",
            " batch_normalization_1 (Bat  (None, 21, 42, 256)       1024      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 21, 42, 256)       0         \n",
            "                                                                 \n",
            " conv2d_3 (Conv2D)           (None, 21, 42, 256)       590080    \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 7, 14, 256)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 7, 14, 256)        0         \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 7, 14, 512)        1180160   \n",
            "                                                                 \n",
            " batch_normalization_2 (Bat  (None, 7, 14, 512)        2048      \n",
            " chNormalization)                                                \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 7, 14, 1024)       4719616   \n",
            "                                                                 \n",
            " max_pooling2d_2 (MaxPoolin  (None, 2, 4, 1024)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 2, 4, 1024)        0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 8192)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 2048)              16779264  \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 4096)              8392704   \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 3)                 12291     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 32865539 (125.37 MB)\n",
            "Trainable params: 32863491 (125.36 MB)\n",
            "Non-trainable params: 2048 (8.00 KB)\n",
            "_________________________________________________________________\n",
            "Epoch 1/60\n",
            "  6/103 [>.............................] - ETA: 5:14 - loss: 4.5396 - accuracy: 0.3125"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[27], line 45\u001b[0m\n\u001b[1;32m     41\u001b[0m model_conv\u001b[38;5;241m.\u001b[39madd(Dense(CLASS_COUNT, activation\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msoftmax\u001b[39m\u001b[38;5;124m'\u001b[39m))\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m# Обучение модели и вывод оценки ее работы на тестовых данных\u001b[39;00m\n\u001b[0;32m---> 45\u001b[0m \u001b[43mcompile_train_eval_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_conv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     46\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     47\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mvalidation_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mclass_labels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mCLASS_LIST\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     50\u001b[0m \u001b[43m                         \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mСверточный классификатор\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
            "Cell \u001b[0;32mIn[26], line 18\u001b[0m, in \u001b[0;36mcompile_train_eval_model\u001b[0;34m(model, train_data, val_data, test_data, class_labels, title, optimizer, epochs, batch_size, graph_size, cm_size)\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompile_train_eval_model\u001b[39m(model,                    \u001b[38;5;66;03m# модель нейронной сети\u001b[39;00m\n\u001b[1;32m      4\u001b[0m                              train_data,               \u001b[38;5;66;03m# обучающие данные\u001b[39;00m\n\u001b[1;32m      5\u001b[0m                              val_data,                 \u001b[38;5;66;03m# проверочные данные\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;66;03m# Компиляция и обучение модели на заданных параметрах\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;66;03m# В качестве проверочных используются тестовые данные\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m     \u001b[43mcompile_train_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m                        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     24\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mfigsize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgraph_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;66;03m# Вывод результатов оценки работы модели на тестовых данных\u001b[39;00m\n\u001b[1;32m     27\u001b[0m     eval_model(model, test_data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m], test_data[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m1\u001b[39m],\n\u001b[1;32m     28\u001b[0m                class_labels\u001b[38;5;241m=\u001b[39mclass_labels,\n\u001b[1;32m     29\u001b[0m                title\u001b[38;5;241m=\u001b[39mtitle,\n\u001b[1;32m     30\u001b[0m                figsize\u001b[38;5;241m=\u001b[39mcm_size)\n",
            "Cell \u001b[0;32mIn[24], line 21\u001b[0m, in \u001b[0;36mcompile_train_model\u001b[0;34m(model, train_data, val_data, optimizer, epochs, batch_size, figsize)\u001b[0m\n\u001b[1;32m     18\u001b[0m model\u001b[38;5;241m.\u001b[39msummary()\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# Обучение модели с заданными параметрами\u001b[39;00m\n\u001b[0;32m---> 21\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     22\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mepochs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     23\u001b[0m \u001b[43m                    \u001b[49m\u001b[38;5;66;43;03m# batch_size=batch_size,\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m                    \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Вывод графиков точности и ошибки\u001b[39;00m\n\u001b[1;32m     27\u001b[0m fig, (ax1, ax2) \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m, figsize\u001b[38;5;241m=\u001b[39mfigsize)\n",
            "File \u001b[0;32m~/Project/AIuniversity/google_colab/.venv/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:65\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 65\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Project/AIuniversity/google_colab/.venv/lib/python3.9/site-packages/keras/src/engine/training.py:1807\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mprofiler\u001b[38;5;241m.\u001b[39mexperimental\u001b[38;5;241m.\u001b[39mTrace(\n\u001b[1;32m   1800\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1801\u001b[0m     epoch_num\u001b[38;5;241m=\u001b[39mepoch,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1804\u001b[0m     _r\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m,\n\u001b[1;32m   1805\u001b[0m ):\n\u001b[1;32m   1806\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1807\u001b[0m     tmp_logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1808\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m data_handler\u001b[38;5;241m.\u001b[39mshould_sync:\n\u001b[1;32m   1809\u001b[0m         context\u001b[38;5;241m.\u001b[39masync_wait()\n",
            "File \u001b[0;32m~/Project/AIuniversity/google_colab/.venv/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
            "File \u001b[0;32m~/Project/AIuniversity/google_colab/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:832\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    829\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    831\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 832\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    834\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    835\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
            "File \u001b[0;32m~/Project/AIuniversity/google_colab/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/polymorphic_function.py:868\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    865\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[1;32m    866\u001b[0m   \u001b[38;5;66;03m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    867\u001b[0m   \u001b[38;5;66;03m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 868\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    869\u001b[0m \u001b[43m      \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_no_variable_creation_config\u001b[49m\n\u001b[1;32m    870\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    871\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_variable_creation_config \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    872\u001b[0m   \u001b[38;5;66;03m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    873\u001b[0m   \u001b[38;5;66;03m# in parallel.\u001b[39;00m\n\u001b[1;32m    874\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n",
            "File \u001b[0;32m~/Project/AIuniversity/google_colab/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[0;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[1;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[0;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[1;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/Project/AIuniversity/google_colab/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/concrete_function.py:1323\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[1;32m   1319\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1320\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1321\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1322\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1323\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1325\u001b[0m     args,\n\u001b[1;32m   1326\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1327\u001b[0m     executing_eagerly)\n\u001b[1;32m   1328\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
            "File \u001b[0;32m~/Project/AIuniversity/google_colab/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[0;34m(self, args)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
            "File \u001b[0;32m~/Project/AIuniversity/google_colab/.venv/lib/python3.9/site-packages/tensorflow/python/eager/polymorphic_function/atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[1;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[0;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[1;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[1;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[1;32m    261\u001b[0m     )\n",
            "File \u001b[0;32m~/Project/AIuniversity/google_colab/.venv/lib/python3.9/site-packages/tensorflow/python/eager/context.py:1486\u001b[0m, in \u001b[0;36mContext.call_function\u001b[0;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[1;32m   1484\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[1;32m   1485\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1486\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1487\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1488\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1489\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1490\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1491\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1492\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1494\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m   1495\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[1;32m   1496\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[1;32m   1501\u001b[0m   )\n",
            "File \u001b[0;32m~/Project/AIuniversity/google_colab/.venv/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Создание последовательной модели\n",
        "model_conv = Sequential()\n",
        "\n",
        "# Первый сверточный слой\n",
        "model_conv.add(\n",
        "    Conv2D(\n",
        "        256,\n",
        "        (3, 3),\n",
        "        padding=\"same\",\n",
        "        activation=\"relu\",\n",
        "        input_shape=(IMG_HEIGHT, IMG_WIDTH, IMG_CHANNELS),\n",
        "    )\n",
        ")\n",
        "model_conv.add(BatchNormalization())\n",
        "\n",
        "# Второй сверточный слой\n",
        "model_conv.add(Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model_conv.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "\n",
        "# Третий сверточный слой\n",
        "model_conv.add(Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model_conv.add(BatchNormalization())\n",
        "model_conv.add(Dropout(0.2))\n",
        "\n",
        "# Четвертый сверточный слой\n",
        "model_conv.add(Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model_conv.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model_conv.add(Dropout(0.2))\n",
        "\n",
        "# Пятый сверточный слой\n",
        "model_conv.add(Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model_conv.add(BatchNormalization())\n",
        "\n",
        "# Шестой сверточный слой\n",
        "model_conv.add(Conv2D(1024, (3, 3), padding=\"same\", activation=\"relu\"))\n",
        "model_conv.add(MaxPooling2D(pool_size=(3, 3)))\n",
        "model_conv.add(Dropout(0.2))\n",
        "\n",
        "# Слой преобразования многомерных данных в одномерные\n",
        "model_conv.add(Flatten())\n",
        "\n",
        "# Промежуточный полносвязный слой\n",
        "model_conv.add(Dense(2048, activation=\"relu\"))\n",
        "\n",
        "# Промежуточный полносвязный слой\n",
        "model_conv.add(Dense(4096, activation=\"relu\"))\n",
        "\n",
        "# Выходной полносвязный слой с количеством нейронов по количесту классов\n",
        "model_conv.add(Dense(CLASS_COUNT, activation=\"softmax\"))\n",
        "\n",
        "\n",
        "# Обучение модели и вывод оценки ее работы на тестовых данных\n",
        "compile_train_eval_model(\n",
        "    model_conv,\n",
        "    train_generator,\n",
        "    validation_generator,\n",
        "    test_generator,\n",
        "    class_labels=CLASS_LIST,\n",
        "    title=\"Сверточный классификатор\",\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Создание архива"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def predict(img_path=\"./test_image_1.jpg\", model_path=\"./model_cars_all.h5\"):\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    IMG_WIDTH = 128  # Ширина изображения для нейросети\n",
        "    IMG_HEIGHT = 64  # Высота изображения для нейросети\n",
        "\n",
        "    # Используем блок with для открытия и автоматического закрытия файла\n",
        "    with Image.open(img_path) as img:\n",
        "        test_image = img.resize((IMG_HEIGHT, IMG_WIDTH))\n",
        "        image = np.array(test_image, dtype=\"float64\") / 255\n",
        "\n",
        "    image = np.expand_dims(image, axis=0)\n",
        "    image = image.reshape(image.shape[0], -1)\n",
        "    cls_image = np.argmax(model.predict(image))\n",
        "\n",
        "    print(cls_image)\n",
        "    # Отрисовка итогового изображения\n",
        "    plt.imshow(test_image, cmap=\"Greys_r\")\n",
        "\n",
        "    # Без сетки\n",
        "    plt.grid(False)\n",
        "\n",
        "    # Без осей\n",
        "    plt.axis(\"off\")\n",
        "\n",
        "    # Вывод результата\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files\n",
        "\n",
        "# Загрузка одного файла\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Загрузка нескольких файлов\n",
        "# uploaded = files.upload()\n",
        "\n",
        "# Пример обработки загруженных файлов\n",
        "for filename, content in uploaded.items():\n",
        "    with open(filename, \"wb\") as f:\n",
        "        f.write(content)\n",
        "\n",
        "print(\"Файлы успешно загружены!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "predict(\"9.jpeg\", \"model_cars_all.h5\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Сохранение кода скрипта в переменной text_code\n",
        "\n",
        "text_code = \"\"\"\n",
        "from tensorflow.keras.models import load_model\n",
        "from PIL import Image, ImageOps\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def predict(img_path=\"./test_image_1.jpg\", model_path=\"./model_mnist_all.h5\"):\n",
        "\n",
        "\n",
        "    model = load_model(model_path)\n",
        "\n",
        "    img_width, img_height = 28, 28\n",
        "\n",
        "    # Используем блок with для открытия и автоматического закрытия файла\n",
        "    with Image.open(img_path) as img:\n",
        "        test_image = ImageOps.grayscale(img)\n",
        "        test_image = ImageOps.invert(test_image)\n",
        "        test_image = test_image.resize((img_height, img_width))\n",
        "        test_image = np.array(test_image, dtype=\"float64\") / 255\n",
        "\n",
        "    image = np.expand_dims(test_image, axis=0)\n",
        "    image = image.reshape(image.shape[0], -1)\n",
        "    cls_image = np.argmax(model.predict(image))\n",
        "\n",
        "    print(cls_image)\n",
        "\"\"\"\n",
        "\n",
        "# Запись содержимого переменной в файл скрипта\n",
        "\n",
        "with open(\"script.py\", \"w\") as f:  # Создание / открытие файла\n",
        "    f.write(text_code)  # Запись в файл значения переменной text_code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Библиотека для работы с файлами\n",
        "from shutil import copyfile\n",
        "import os\n",
        "\n",
        "output_folder = \"class_images\"\n",
        "os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "for i in range(10):\n",
        "    img_filename = os.path.join(output_folder, f\"class_{i}.jpeg\")\n",
        "    plt.savefig(img_filename)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "label_txt = \"\"\"\n",
        "\n",
        "0\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "8\n",
        "9\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "with open(\"label.txt\", \"w\") as f:  # Создание / открытие файла\n",
        "    f.write(label_txt.strip())  # Запись в файл значения переменной"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import os\n",
        "from zipfile import ZipFile as Zip  # Модуль для работы с zip-архивами\n",
        "\n",
        "# Список всех файлов\n",
        "integrate_files = [\n",
        "    \"model_mnist_all.h5\",\n",
        "    \"script.py\",\n",
        "    \"label.txt\",\n",
        "    *[f\"{i}.jpeg\" for i in range(0, 10)],\n",
        "]\n",
        "\n",
        "zipArchive = Zip(\n",
        "    \"/content/archive.zip\", \"w\"\n",
        ")  # Открытие файла, если такого не существует - будет создан новый\n",
        "\n",
        "for file in integrate_files:  # Для всех всем нужных файлов:\n",
        "    if os.path.exists(file):  # Если файл существует,\n",
        "        zipArchive.write(file)  # то добавление его в архив\n",
        "    else:\n",
        "        print(\n",
        "            f\"Файл {file} отсутствует!\"\n",
        "        )  # иначе вывод на экран названия отсутствующего файла\n",
        "\n",
        "zipArchive.close()  # В финале архив следует закрыть, как и обычный файл"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from google.colab import files  # Функция для скачивания данных на локальный компьютер\n",
        "\n",
        "files.download(filename=\"archive.zip\")  # Скачивание готового архива\n",
        "\n",
        "print(\"Архив загружен\")"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
